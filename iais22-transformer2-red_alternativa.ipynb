{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66c97b0f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-06-27T11:21:54.666835Z",
     "iopub.status.busy": "2022-06-27T11:21:54.666315Z",
     "iopub.status.idle": "2022-06-27T11:22:13.978206Z",
     "shell.execute_reply": "2022-06-27T11:22:13.977127Z"
    },
    "papermill": {
     "duration": 19.321419,
     "end_time": "2022-06-27T11:22:13.980917",
     "exception": false,
     "start_time": "2022-06-27T11:21:54.659498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting timm\r\n",
      "  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.5/431.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm) (0.12.0)\r\n",
      "Requirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.7/site-packages (from timm) (1.11.0)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm) (4.2.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (2.27.1)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (9.1.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (1.21.6)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->timm) (2.0.12)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->timm) (1.26.9)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->timm) (2022.5.18.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->timm) (3.3)\r\n",
      "Installing collected packages: timm\r\n",
      "Successfully installed timm-0.5.4\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader,Dataset, sampler, random_split\n",
    "from torchvision import models\n",
    "!pip install timm # kaggle doesnt have it installed by default\n",
    "import timm\n",
    "from timm.loss import LabelSmoothingCrossEntropy # This is better than normal nn.CrossEntropyLoss\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import copy\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from PIL import Image\n",
    "import glob \n",
    "import math\n",
    "from typing import Any, Callable, cast, Dict, List, Optional, Tuple, Union\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a323ceb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T11:22:13.993264Z",
     "iopub.status.busy": "2022-06-27T11:22:13.992507Z",
     "iopub.status.idle": "2022-06-27T11:22:13.997531Z",
     "shell.execute_reply": "2022-06-27T11:22:13.996601Z"
    },
    "papermill": {
     "duration": 0.012926,
     "end_time": "2022-06-27T11:22:13.999413",
     "exception": false,
     "start_time": "2022-06-27T11:22:13.986487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Método para obtener todas las especies de pájaros a partir de la estructura de carpetas\n",
    "def get_classes(data_dir):\n",
    "    all_data = datasets.ImageFolder(data_dir)\n",
    "    return all_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c200c442",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T11:22:14.009969Z",
     "iopub.status.busy": "2022-06-27T11:22:14.009714Z",
     "iopub.status.idle": "2022-06-27T11:22:14.021959Z",
     "shell.execute_reply": "2022-06-27T11:22:14.021284Z"
    },
    "papermill": {
     "duration": 0.019379,
     "end_time": "2022-06-27T11:22:14.023592",
     "exception": false,
     "start_time": "2022-06-27T11:22:14.004213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Método para entrenar el modelo\n",
    "def train_model(model, criterion, optimizer, scheduler, dataloaders, dataset_sizes, num_epochs=10):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print(\"-\"*10)\n",
    "        \n",
    "        for phase in ['train', 'val']: \n",
    "            if phase == 'train':\n",
    "                model.train() # model to training mode\n",
    "            else:\n",
    "                model.eval() # model to evaluate\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0.0\n",
    "            \n",
    "            for inputs, labels in tqdm(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'): # no autograd makes validation go faster\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1) # used for accuracy\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            if phase == 'train':\n",
    "                scheduler.step() # step at end of epoch\n",
    "            \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc =  running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "            print(\"{} Loss: {:.4f} Acc: {:.4f}\".format(phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict()) # keep the best validation accuracy model\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since # slight error\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print(\"Best Val Acc: {:.4f}\".format(best_acc))\n",
    "    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4755e9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T11:22:14.033915Z",
     "iopub.status.busy": "2022-06-27T11:22:14.033676Z",
     "iopub.status.idle": "2022-06-27T11:22:14.039982Z",
     "shell.execute_reply": "2022-06-27T11:22:14.039365Z"
    },
    "papermill": {
     "duration": 0.013577,
     "end_time": "2022-06-27T11:22:14.041786",
     "exception": false,
     "start_time": "2022-06-27T11:22:14.028209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pre_image(image_path,model):\n",
    "    #img = Image.open(image_path)\n",
    "    #transform_norm = transforms.Compose([transforms.ToTensor(), \n",
    "    #transforms.Resize((224,224))])\n",
    "    transform_norm = transforms.ToTensor()\n",
    "   # get normalized image\n",
    "    img_normalized = transform_norm(image_path).float()\n",
    "    img_normalized = img_normalized.unsqueeze(0)\n",
    "   # input = Variable(image_tensor)\n",
    "    img_normalized = img_normalized.to(device)\n",
    "   # print(img_normalized.shape)\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        output =model(img_normalized)\n",
    "     # print(output)\n",
    "        index = output.data.cpu().numpy().argmax()\n",
    "        class_name = classes[index]\n",
    "        return class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92658623",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T11:22:14.052586Z",
     "iopub.status.busy": "2022-06-27T11:22:14.052324Z",
     "iopub.status.idle": "2022-06-27T11:22:14.069761Z",
     "shell.execute_reply": "2022-06-27T11:22:14.068979Z"
    },
    "papermill": {
     "duration": 0.025236,
     "end_time": "2022-06-27T11:22:14.071597",
     "exception": false,
     "start_time": "2022-06-27T11:22:14.046361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "IMG_EXTENSIONS = (\".jpg\", \".jpeg\", \".png\", \".ppm\", \".bmp\", \".pgm\", \".tif\", \".tiff\", \".webp\")\n",
    "\n",
    "class ImageFolderCustom(datasets.DatasetFolder):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        setname: str,\n",
    "        transform: Optional[Callable] = None,\n",
    "        target_transform: Optional[Callable] = None,\n",
    "        loader: Callable[[str], Any] = datasets.folder.default_loader,\n",
    "        is_valid_file: Optional[Callable[[str], bool]] = None,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            root,\n",
    "            loader,\n",
    "            IMG_EXTENSIONS if is_valid_file is None else None,\n",
    "            transform=transform,\n",
    "            target_transform=target_transform,\n",
    "            is_valid_file=is_valid_file,\n",
    "        )\n",
    "        \n",
    "        classes, class_to_idx = self.find_classes(self.root)\n",
    "        self.samples = self.make_dataset2(self.root,setname, class_to_idx, IMG_EXTENSIONS, is_valid_file)\n",
    "        self.imgs = self.samples\n",
    "        \n",
    "    @staticmethod\n",
    "    def make_dataset2(\n",
    "        directory: str,\n",
    "        setname: str,\n",
    "        class_to_idx: Optional[Dict[str, int]] = None,\n",
    "        extensions: Optional[Union[str, Tuple[str, ...]]] = None,\n",
    "        is_valid_file: Optional[Callable[[str], bool]] = None,    \n",
    "    ) -> List[Tuple[str, int]]:\n",
    "        \n",
    "        setname = setname\n",
    "        assert setname in ['train','val']\n",
    "\n",
    "        if class_to_idx is None:\n",
    "            _, class_to_idx = find_classes(directory)\n",
    "        elif not class_to_idx:\n",
    "            raise ValueError(\"'class_to_index' must have at least one entry to collect any samples.\")\n",
    "\n",
    "        both_none = extensions is None and is_valid_file is None\n",
    "        both_something = extensions is not None and is_valid_file is not None\n",
    "        if both_none or both_something:\n",
    "            raise ValueError(\"Both extensions and is_valid_file cannot be None or not None at the same time\")\n",
    "\n",
    "        if extensions is not None:\n",
    "\n",
    "            def is_valid_file(x: str) -> bool:\n",
    "                return datasets.folder.has_file_allowed_extension(x, extensions)  # type: ignore[arg-type]\n",
    "\n",
    "        is_valid_file = cast(Callable[[str], bool], is_valid_file)\n",
    "\n",
    "        instances = []\n",
    "        available_classes = set()\n",
    "        for target_class in sorted(class_to_idx.keys()):\n",
    "            class_index = class_to_idx[target_class]\n",
    "            target_dir = os.path.join(directory, target_class)\n",
    "            if not os.path.isdir(target_dir):\n",
    "                continue\n",
    "            for root, _, fnames in sorted(os.walk(target_dir, followlinks=True)):\n",
    "                num_images=len(fnames)\n",
    "                num_separator=math.ceil(num_images*0.9)\n",
    "                i=0\n",
    "                #print(i, num_separator)\n",
    "                #print(setname=='train' and i>=0 and i<num_separator)\n",
    "                for fname in sorted(fnames):\n",
    "                    path = os.path.join(root, fname)\n",
    "                    #print(i)\n",
    "                    if(setname=='train' and i>=0 and i<num_separator or (setname=='val' and i>=num_separator and i<num_images)):\n",
    "                        if is_valid_file(path):\n",
    "                            item = path, class_index\n",
    "                            #print(item)\n",
    "                            instances.append(item)\n",
    "                            if target_class not in available_classes:\n",
    "                                available_classes.add(target_class)\n",
    "                    i=i+1\n",
    "    \n",
    "        empty_classes = set(class_to_idx.keys()) - available_classes\n",
    "        if empty_classes:\n",
    "            msg = f\"Found no valid file for the classes {', '.join(sorted(empty_classes))}. \"\n",
    "            if extensions is not None:\n",
    "                msg += f\"Supported extensions are: {extensions if isinstance(extensions, str) else ', '.join(extensions)}\"\n",
    "            raise FileNotFoundError(msg)\n",
    "    \n",
    "        return instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e54c587",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T11:22:14.081745Z",
     "iopub.status.busy": "2022-06-27T11:22:14.081509Z",
     "iopub.status.idle": "2022-06-27T11:22:14.089379Z",
     "shell.execute_reply": "2022-06-27T11:22:14.088584Z"
    },
    "papermill": {
     "duration": 0.014997,
     "end_time": "2022-06-27T11:22:14.091181",
     "exception": false,
     "start_time": "2022-06-27T11:22:14.076184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*53*53,8000)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(8000, 2000)\n",
    "        self.fc3 = nn.Linear(2000, 400)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        \n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1971eca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T11:22:14.101232Z",
     "iopub.status.busy": "2022-06-27T11:22:14.100975Z",
     "iopub.status.idle": "2022-06-27T11:22:29.434520Z",
     "shell.execute_reply": "2022-06-27T11:22:29.433104Z"
    },
    "papermill": {
     "duration": 15.341255,
     "end_time": "2022-06-27T11:22:29.436974",
     "exception": false,
     "start_time": "2022-06-27T11:22:14.095719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 52714 images for training with 400 classes\n",
      "Found 5674 images for validation with 400 classes\n",
      "Found 58388 images for final training with 400 classes\n"
     ]
    }
   ],
   "source": [
    "\n",
    " #train\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "    \n",
    "train_data = ImageFolderCustom(root='../input/iais22-birds/birds/birds',setname='train', transform = transform_train)\n",
    "train_loader = DataLoader(train_data, batch_size=256, shuffle=True, num_workers=4)\n",
    "train_data_len = len(train_data)\n",
    "\n",
    "val_data = ImageFolderCustom(root='../input/iais22-birds/birds/birds',setname='val', transform = transform_val)\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=True, num_workers=4)\n",
    "valid_data_len = len(val_data)\n",
    "\n",
    "print(f\"Found {len(train_data)} images for training with {len(train_data.classes)} classes\")\n",
    "print(f\"Found {len(val_data)} images for validation with {len(val_data.classes)} classes\")\n",
    "\n",
    "final_train_data = datasets.ImageFolder(root='../input/iais22-birds/birds/birds', transform = transform_train)\n",
    "final_train_loader = DataLoader(final_train_data, batch_size=256, shuffle=True, num_workers=4)\n",
    "final_train_data_len = len(final_train_data)\n",
    "\n",
    "print(f\"Found {len(final_train_data)} images for final training with {len(final_train_data.classes)} classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3896e9d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T11:22:29.449996Z",
     "iopub.status.busy": "2022-06-27T11:22:29.449309Z",
     "iopub.status.idle": "2022-06-27T11:22:29.454275Z",
     "shell.execute_reply": "2022-06-27T11:22:29.453415Z"
    },
    "papermill": {
     "duration": 0.013025,
     "end_time": "2022-06-27T11:22:29.456068",
     "exception": false,
     "start_time": "2022-06-27T11:22:29.443043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    \"train\": train_loader,\n",
    "    \"val\": val_loader\n",
    "}\n",
    "dataset_sizes = {\n",
    "    \"train\": train_data_len,\n",
    "    \"val\": valid_data_len\n",
    "}\n",
    "\n",
    "final_dataloaders = {\n",
    "    \"train\": final_train_loader,\n",
    "    \"val\": val_loader\n",
    "}\n",
    "final_dataset_sizes = {\n",
    "    \"train\": final_train_data_len,\n",
    "    \"val\": valid_data_len\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c56ebf2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T11:22:29.466752Z",
     "iopub.status.busy": "2022-06-27T11:22:29.466499Z",
     "iopub.status.idle": "2022-06-27T11:22:29.892837Z",
     "shell.execute_reply": "2022-06-27T11:22:29.892004Z"
    },
    "papermill": {
     "duration": 0.434055,
     "end_time": "2022-06-27T11:22:29.894951",
     "exception": false,
     "start_time": "2022-06-27T11:22:29.460896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes = get_classes(\"../input/iais22-birds/birds/birds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff14b237",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T11:22:29.906626Z",
     "iopub.status.busy": "2022-06-27T11:22:29.906339Z",
     "iopub.status.idle": "2022-06-27T11:22:38.655437Z",
     "shell.execute_reply": "2022-06-27T11:22:38.654581Z"
    },
    "papermill": {
     "duration": 8.757494,
     "end_time": "2022-06-27T11:22:38.657602",
     "exception": false,
     "start_time": "2022-06-27T11:22:29.900108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "model = Net(dropout=0.2).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f499651d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T11:22:38.668894Z",
     "iopub.status.busy": "2022-06-27T11:22:38.668608Z",
     "iopub.status.idle": "2022-06-27T11:22:38.674695Z",
     "shell.execute_reply": "2022-06-27T11:22:38.673833Z"
    },
    "papermill": {
     "duration": 0.013659,
     "end_time": "2022-06-27T11:22:38.676487",
     "exception": false,
     "start_time": "2022-06-27T11:22:38.662828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.11)\n",
    "criterion = criterion.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3477156",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T11:22:38.687669Z",
     "iopub.status.busy": "2022-06-27T11:22:38.687196Z",
     "iopub.status.idle": "2022-06-27T11:22:38.691066Z",
     "shell.execute_reply": "2022-06-27T11:22:38.690318Z"
    },
    "papermill": {
     "duration": 0.01156,
     "end_time": "2022-06-27T11:22:38.692825",
     "exception": false,
     "start_time": "2022-06-27T11:22:38.681265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a642d591",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T11:22:38.703467Z",
     "iopub.status.busy": "2022-06-27T11:22:38.703224Z",
     "iopub.status.idle": "2022-06-27T11:22:38.707824Z",
     "shell.execute_reply": "2022-06-27T11:22:38.707175Z"
    },
    "papermill": {
     "duration": 0.011776,
     "end_time": "2022-06-27T11:22:38.709460",
     "exception": false,
     "start_time": "2022-06-27T11:22:38.697684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Entrenamiento con separación de datos\n",
    "#model_ft = train_model(model, criterion, optimizer, exp_lr_scheduler, dataloaders, dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc9b5099",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T11:22:38.720185Z",
     "iopub.status.busy": "2022-06-27T11:22:38.719615Z",
     "iopub.status.idle": "2022-06-27T11:48:14.427574Z",
     "shell.execute_reply": "2022-06-27T11:48:14.424455Z"
    },
    "papermill": {
     "duration": 1535.715179,
     "end_time": "2022-06-27T11:48:14.429412",
     "exception": false,
     "start_time": "2022-06-27T11:22:38.714233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [02:59<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 5.6329 Acc: 0.0209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89/89 [00:12<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 5.0363 Acc: 0.0647\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [02:07<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 4.6176 Acc: 0.1293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89/89 [00:12<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 4.2386 Acc: 0.1956\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [02:07<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 4.0208 Acc: 0.2511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89/89 [00:12<00:00,  6.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 3.7529 Acc: 0.3107\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [02:06<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 3.5903 Acc: 0.3492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89/89 [00:12<00:00,  7.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 3.3643 Acc: 0.3955\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [02:14<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 3.2585 Acc: 0.4272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89/89 [00:13<00:00,  6.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 2.9989 Acc: 0.4880\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [02:19<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 2.9810 Acc: 0.5017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89/89 [00:12<00:00,  7.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 2.7662 Acc: 0.5585\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [02:15<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 2.7166 Acc: 0.5739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89/89 [00:13<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 2.5129 Acc: 0.6403\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [02:23<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 2.4812 Acc: 0.6441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89/89 [00:16<00:00,  5.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 2.2912 Acc: 0.7145\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [02:23<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 2.2467 Acc: 0.7201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89/89 [00:12<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 2.0481 Acc: 0.7956\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [02:26<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 2.0274 Acc: 0.7947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89/89 [00:13<00:00,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.8285 Acc: 0.8717\n",
      "\n",
      "Training complete in 25m 36s\n",
      "Best Val Acc: 0.8717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Entrenamiento con todos los datos\n",
    "model_ft = train_model(model, criterion, optimizer, exp_lr_scheduler, final_dataloaders, final_dataset_sizes,num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33084101",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T11:48:14.806552Z",
     "iopub.status.busy": "2022-06-27T11:48:14.806164Z",
     "iopub.status.idle": "2022-06-27T11:52:42.196336Z",
     "shell.execute_reply": "2022-06-27T11:52:42.195552Z"
    },
    "papermill": {
     "duration": 267.773023,
     "end_time": "2022-06-27T11:52:42.385556",
     "exception": false,
     "start_time": "2022-06-27T11:48:14.612533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8421278</td>\n",
       "      <td>MAGPIE GOOSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9541931</td>\n",
       "      <td>SHORT BILLED DOWITCHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1820866</td>\n",
       "      <td>FLAME BOWERBIRD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12992</td>\n",
       "      <td>BARRED PUFFBIRD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12761483</td>\n",
       "      <td>PELICAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                Category\n",
       "0   8421278            MAGPIE GOOSE\n",
       "1   9541931  SHORT BILLED DOWITCHER\n",
       "2   1820866         FLAME BOWERBIRD\n",
       "3     12992         BARRED PUFFBIRD\n",
       "4  12761483                 PELICAN"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "image_list = []\n",
    "preds_id = []\n",
    "for filename in glob.glob(\"../input/iais22-birds/submission_test/submission_test/*.jpg\"): \n",
    "    im=Image.open(filename)\n",
    "    id = os.path.basename(filename).split(\".\")[0]\n",
    "    image_list.append(im)\n",
    "    preds_id.append(id)\n",
    "\n",
    "index=[]\n",
    "preds = []\n",
    "for f in image_list:\n",
    "    i = image_list.index(f)+1\n",
    "    predict_class = pre_image(f,model)\n",
    "    index.append(i)\n",
    "    preds.append(predict_class)\n",
    "    if(i%500==0):\n",
    "        print(i)\n",
    "\n",
    "submission = pd.DataFrame(\n",
    "    data =np.array([preds_id,preds ]).T, \n",
    "    columns = [\"Id\", \"Category\"]\n",
    ")\n",
    "submission.to_csv(\"submission.csv\", index = False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9e0613e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T11:52:42.754814Z",
     "iopub.status.busy": "2022-06-27T11:52:42.754443Z",
     "iopub.status.idle": "2022-06-27T11:52:47.635645Z",
     "shell.execute_reply": "2022-06-27T11:52:47.634674Z"
    },
    "papermill": {
     "duration": 5.069525,
     "end_time": "2022-06-27T11:52:47.637899",
     "exception": false,
     "start_time": "2022-06-27T11:52:42.568374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"modelo_red_alternativa.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1866.482411,
   "end_time": "2022-06-27T11:52:52.771322",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-27T11:21:46.288911",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
